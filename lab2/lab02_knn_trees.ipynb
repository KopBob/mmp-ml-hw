{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2. Метод ближайших соседей и решающие деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Копин Борис Александрович\n",
    "\n",
    "Группа: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все эксперименты в этой лабораторной работе предлагается проводить на данных соревнования Amazon Employee Access Challenge: https://www.kaggle.com/c/amazon-employee-access-challenge\n",
    "\n",
    "В данной задаче предлагается предсказать, будет ли одобрен запрос сотрудника на получение доступа к тому или иному ресурсу. Все признаки являются категориальными.\n",
    "\n",
    "Для удобства данные можно загрузить по ссылке: https://www.dropbox.com/s/q6fbs1vvhd5kvek/amazon.csv\n",
    "\n",
    "Сразу прочитаем данные и создадим разбиение на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39353</td>\n",
       "      <td>85475</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>123472</td>\n",
       "      <td>117905</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>117908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17183</td>\n",
       "      <td>1540</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>123125</td>\n",
       "      <td>118536</td>\n",
       "      <td>118536</td>\n",
       "      <td>308574</td>\n",
       "      <td>118539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>36724</td>\n",
       "      <td>14457</td>\n",
       "      <td>118219</td>\n",
       "      <td>118220</td>\n",
       "      <td>117884</td>\n",
       "      <td>117879</td>\n",
       "      <td>267952</td>\n",
       "      <td>19721</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36135</td>\n",
       "      <td>5396</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>119993</td>\n",
       "      <td>118321</td>\n",
       "      <td>240983</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>42680</td>\n",
       "      <td>5905</td>\n",
       "      <td>117929</td>\n",
       "      <td>117930</td>\n",
       "      <td>119569</td>\n",
       "      <td>119323</td>\n",
       "      <td>123932</td>\n",
       "      <td>19793</td>\n",
       "      <td>119325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "0       1     39353   85475         117961         118300         123472   \n",
       "1       1     17183    1540         117961         118343         123125   \n",
       "2       1     36724   14457         118219         118220         117884   \n",
       "3       1     36135    5396         117961         118343         119993   \n",
       "4       1     42680    5905         117929         117930         119569   \n",
       "\n",
       "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "0      117905            117906       290919     117908  \n",
       "1      118536            118536       308574     118539  \n",
       "2      117879            267952        19721     117880  \n",
       "3      118321            240983       290919     118322  \n",
       "4      119323            123932        19793     119325  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('amazon.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94210992096188473"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# доля положительных примеров\n",
    "data.ACTION.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION 2\n",
      "RESOURCE 7518\n",
      "MGR_ID 4243\n",
      "ROLE_ROLLUP_1 128\n",
      "ROLE_ROLLUP_2 177\n",
      "ROLE_DEPTNAME 449\n",
      "ROLE_TITLE 343\n",
      "ROLE_FAMILY_DESC 2358\n",
      "ROLE_FAMILY 67\n",
      "ROLE_CODE 343\n"
     ]
    }
   ],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print col_name, len(data[col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "features = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: kNN и категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на втором семинаре. Реализуйте самостоятельно метод k ближайших соседей, который будет уметь работать с этими функциями расстояния (учитите, что он должен возвращать вероятность — отношение объектов первого класса среди соседей к числу соседей). Как вариант, можно реализовать метрики как [user-defined distance](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html), после чего воспользоваться реализацией kNN из sklearn (в этом случае используйте функцию predict_proba).\n",
    "\n",
    "#### Подсчитайте для каждой из метрик качество на тестовой выборке `X_test` при числе соседей $k = 10$. Мера качества — AUC-ROC.\n",
    "\n",
    "Какая функция расстояния оказалась лучшей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class KNeighborsClassifier(object):\n",
    "    \n",
    "    def __init__(self, dist_func='overlap', feature_weights=None, **kwargs):\n",
    "        self.dist_func = dist_func\n",
    "        \n",
    "    def fit(self, X, y=None, feature_weights=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_objects, n_features)\n",
    "            List of n_features-dimensional data points.  Each row\n",
    "            corresponds to a single data point.\n",
    "        \"\"\"\n",
    "        self._fit_X = X\n",
    "        self._fit_y = y\n",
    "        self.classes = set(y)\n",
    "        self.feature_weights = feature_weights or np.ones(X.shape[1])\n",
    "        self._sorted_neighbors = None\n",
    "    \n",
    "    \n",
    "    def fit_with_pred(self, X):\n",
    "        print \"Find coincidence features\"\n",
    "        coincidence_matrix = X[:,np.newaxis]==self._fit_X[np.newaxis,:]\n",
    "        \n",
    "        print \"Compute dist(self._fit_X, X)\"\n",
    "        dist_func = _dist_funcs[self.dist_func]\n",
    "        dist_matrix = dist_func(self, X, coincidence_matrix)\n",
    "        \n",
    "        print \"Get class indices\"\n",
    "        nearest_X_fit_indices = np.argsort(dist_matrix, axis=1)\n",
    "        \n",
    "        print \"Sort and save neighbors\"\n",
    "        self._sorted_neighbors_idxs = self._fit_y[nearest_X_fit_indices]\n",
    "        \n",
    "    \n",
    "    def predict(self, k):\n",
    "        k_nearest_neighbors = self._sorted_neighbors_idxs[:, :k]\n",
    "        \n",
    "        score = np.array([np.sum(k_nearest_neighbors == c, axis=1) for c in self.classes]).T\n",
    "        X_y = np.argmax(score, axis=1)\n",
    "        \n",
    "        return X_y\n",
    "    \n",
    "    def _load_sorted_neighbors_idxs(self, sorted_neighbors_idxs):\n",
    "        self._sorted_neighbors_idxs = sorted_neighbors_idxs\n",
    "\n",
    "\n",
    "def _overlap_dist(KNN, X, coincidence_matrix):\n",
    "    print \"_overlap_dist\"\n",
    "    weighted_coincidence_matrix = coincidence_matrix * KNN.feature_weights\n",
    "    \n",
    "    print \"Sum Feature distance\"\n",
    "    dist_matrix = np.sum(weighted_coincidence_matrix, axis=2)\n",
    "    \n",
    "    return dist_matrix\n",
    "\n",
    "\n",
    "def _get_accumulated_p_2(f, l):\n",
    "    print \"_get_accumulated_p_2\"\n",
    "    p   = [Counter({v: f_v / float(l) for v, f_v in c.items()}) for c in f]\n",
    "    p_2 = [Counter({v: f_v*(f_v - 1)/float(l*(l-1)) for v, f_v in c.items()}) for c in f]\n",
    "    \n",
    "    A_dtype=[('x', int), ('p', float), ('p2', float)]\n",
    "    A_order = 'p'\n",
    "    A = []\n",
    "    for i, c in enumerate(f):\n",
    "        u = np.array([(k, p[i].get(k), p_2[i].get(k)) for k in c.keys()], dtype=A_dtype)\n",
    "        u.sort(order=A_order)\n",
    "        A.append(np.array(u.tolist()[::-1]))\n",
    "\n",
    "    # cumulative sum over p_2\n",
    "    B = [np.column_stack( [ f_A , np.cumsum(f_A, axis=0)[:,2] ] ) for f_A in A] \n",
    "    \n",
    "    # extract p_2 only\n",
    "    P_2 = [Counter({int(x):f_B[i, 3] for i, x in enumerate(f_B[:,0])}) for f_B in B]\n",
    "    \n",
    "    return P_2\n",
    "\n",
    "def _smooth_overlap_dist(KNN, X, coincidence_matrix):\n",
    "    print \"_smooth_overlap_dist\"\n",
    "    f = [Counter(c) for c in KNN._fit_X.T]\n",
    "    \n",
    "    accum_p_2 = _get_accumulated_p_2(f, KNN._fit_X.shape[0])\n",
    "    \n",
    "    # Extend each X \n",
    "    print \"Extend each X \"\n",
    "    X_accum_p_2 = [[accum_p_2[i].get(feature) for i, feature in enumerate(x)] for x in KNN._fit_X]\n",
    "    X_accum_p_2 = np.array(X_accum_p_2)\n",
    "    \n",
    "    print \"Get P_2\"\n",
    "    idx_coincidence_features = np.nonzero(coincidence_matrix)\n",
    "    X_coincidence_idx = (idx_coincidence_features[1], idx_coincidence_features[2])\n",
    "    \n",
    "    print \"Feature distance\"\n",
    "    dist_matrix = np.ones((X.shape[0], KNN._fit_X.shape[0], KNN._fit_X.shape[1]))\n",
    "    dist_matrix[idx_coincidence_features] = X_accum_p_2[X_coincidence_idx]\n",
    "    \n",
    "    print \"Sum Feature distance\"\n",
    "    dist_matrix_sum = np.sum(dist_matrix, axis=2)\n",
    "        \n",
    "    return dist_matrix_sum\n",
    "\n",
    "def _map_to_log_f(x):\n",
    "    print \"_map_to_log_f\"\n",
    "    f_x = [Counter(c) for c in x.T]\n",
    "    log_f_x = [Counter({v: np.log(c) for v, c in f.items()}) for f in f_x]\n",
    "    x_log_f = [[log_f_x[f_i].get(f) for f_i, f in enumerate(obj)] for obj in x]\n",
    "    return np.array(x_log_f)\n",
    "    \n",
    "def _type3_dist(KNN, X, coincidence_matrix):\n",
    "    print \"_type3_dist\"\n",
    "    fit_X_log_f = _map_to_log_f(KNN._fit_X)\n",
    "    X_log_f = _map_to_log_f(X)\n",
    "    \n",
    "    print \"np.dot(X_log_f, fit_X_log_f.T)\"\n",
    "    a_b_f = np.dot(X_log_f, fit_X_log_f.T)\n",
    "\n",
    "    x = KNN._fit_X\n",
    "    y = X\n",
    "    A = coincidence_matrix\n",
    "\n",
    "    print \"Step 1\"\n",
    "    A_x = A.reshape(y.shape[0], x.size)*fit_X_log_f.reshape(1, x.size)\n",
    "    A_x = A_x.reshape(y.shape[0], x.shape[0], x.shape[1])\n",
    "\n",
    "    print \"Step 2\"\n",
    "    A_x_T = A_x.swapaxes(0, 1)\n",
    "    A_x_T_slab = A_x_T.reshape(len(x), len(y)*x.shape[1])\n",
    "\n",
    "    print \"Step 3\"\n",
    "    A_x_y_T_slab = A_x_T_slab * X_log_f.reshape(1, y.size)\n",
    "\n",
    "    print \"Step 4\"\n",
    "    A_x_y_T = A_x_y_T_slab.reshape(len(x), len(y), x.shape[1])\n",
    "    A_x_y = A_x_y_T.swapaxes(1, 0)\n",
    "\n",
    "    print \"Step 5\"\n",
    "    A_x_y_sum = np.sum(A_x_y, axis=2)\n",
    "\n",
    "    print \"Step 6\"\n",
    "    dist_matrix = a_b_f - A_x_y_sum\n",
    "    \n",
    "    return dist_matrix\n",
    "    \n",
    "    \n",
    "\n",
    "_dist_funcs = {\n",
    "    'overlap': _overlap_dist,\n",
    "    'smooth_overlap': _smooth_overlap_dist,\n",
    "    'type3': _type3_dist,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_overlap = KNeighborsClassifier(dist_func=\"overlap\")\n",
    "knn_overlap.fit(X_train.as_matrix(), y_train.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find coincidence features\n",
      "Compute dist(self._fit_X, X)\n",
      "_overlap_dist\n",
      "Sum Feature distance\n",
      "Get class indices\n",
      "Sort and save neighbors\n",
      "1 loops, best of 1: 1min 24s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "knn_overlap.fit_with_pred(X_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96836140406107352"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn_overlap.predict(k=10)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save overlap_neighbors_idxs\n",
    "np.savez(\"overlap_neighbors_idxs.dat\",\n",
    "         overlap_neighbors_idxs=knn_overlap._sorted_neighbors_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_smooth_overlap = KNeighborsClassifier(dist_func=\"smooth_overlap\")\n",
    "knn_smooth_overlap.fit(X_train.as_matrix(), y_train.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find coincidence features\n",
      "Compute dist(self._fit_X, X)\n",
      "_smooth_overlap_dist\n",
      "_get_accumulated_p_2\n",
      "Extend each X \n",
      "Get P_2\n",
      "Feature distance\n",
      "Sum Feature distance\n",
      "Get class indices\n",
      "Sort and save neighbors\n",
      "1 loops, best of 1: 2min 56s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "knn_smooth_overlap.fit_with_pred(X_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9711824755423224"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn_smooth_overlap.predict(k=10)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save overlap_neighbors_idxs\n",
    "np.savez(\"smooth_overlap_neighbors_idxs.dat\",\n",
    "         smooth_overlap_neighbors_idxs=knn_smooth_overlap._sorted_neighbors_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_type3 = KNeighborsClassifier(dist_func=\"type3\")\n",
    "knn_type3.fit(X_train.as_matrix(), y_train.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find coincidence features\n",
      "Compute dist(self._fit_X, X)\n",
      "_type3_dist\n",
      "_map_to_log_f\n",
      "_map_to_log_f\n",
      "np.dot(X_log_f, fit_X_log_f.T)\n",
      "Step 1\n",
      "Step 2\n",
      "Step 3\n",
      "Step 4\n",
      "Step 5\n",
      "Step 6\n",
      "Get class indices\n",
      "Sort and save neighbors\n",
      "1 loops, best of 1: 3min 51s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "knn_type3.fit_with_pred(X_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97050225883603514"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn_type3.predict(k=10)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save overlap_neighbors_idxs\n",
    "np.savez(\"type3_neighbors_idxs.dat\",\n",
    "         type3_neighbors_idxs=knn_type3._sorted_neighbors_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore overlap_neighbors_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overlap_neighbors_idxs = np.load('overlap_neighbors_idxs.dat.npz')['overlap_neighbors_idxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(dist_func=\"overlap\")\n",
    "knn.fit(X_train.as_matrix(), y_train.as_matrix())\n",
    "knn._load_sorted_neighbors_idxs(overlap_neighbors_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(k=10)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 (бонус). Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какое наилучшее качество удалось достичь?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Реализуйте счетчики (http://blogs.technet.com/b/machinelearning/archive/2015/02/17/big-learning-made-easy-with-counts.aspx), которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, каждый категориальный признак нужно заменить на три: \n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "2. Число `clicks` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "3. Сглаженное отношение двух предыдущих величин: (`clicks` + 1) / (`counts` + 2).\n",
    "\n",
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `clicks` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанный по всей обучающей выборке. Реализуйте и такой вариант. Можно использовать $n = 3$.\n",
    "\n",
    "#### Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Добавьте в исходную выборку парные признаки — то есть для каждой пары $f_i$, $f_j$ исходных категориальных признаков добавьте новый категориальный признак $f_{ij}$, значение которого является конкатенацией значений $f_i$ и $f_j$. Посчитайте счетчики для этой выборки, найдите качество метода $k$ ближайших соседей с наилучшим $k$ (с фолдингом и без)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Решающие деревья и леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Возьмите из предыдущей части выборку с парными признаками, преобразованную с помощью счетчиков без фолдинга. Настройте решающее дерево, подобрав оптимальные значения параметров `max_depth` и `min_samples_leaf`. Какой наилучший AUC-ROC на контроле удалось получить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Настройте случайный лес, подобрав оптимальное число деревьев `n_estimators`. Какое качество на тестовой выборке он дает?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Возьмите выборку с парными признаками, для которой счетчики посчитаны с фолдингом. Обучите на ней случайный лес, подобрав число деревьев. Какое качество на тестовой выборке он дает? Чем вы можете объяснить изменение результата по сравнению с предыдущим пунктом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
